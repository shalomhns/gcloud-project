#LAB:Google Cloud Fundamentals: Getting Started with GKE

#Objectives:In this lab, you learn how to perform the following tasks:

    -Provision a Kubernetes cluster using Kubernetes Engine.
    -Deploy and manage Docker containers using kubectl.

1: Confirm that needed APIs are enabled
    #Enter the following to display the project IDs for your Google Cloud projects: 

            gcloud projects list

    #Using the applicable project ID from the previous step, set the default project to the one in which you want to enable the API

            gcloud config set project YOUR_PROJECT_ID

    #Get a list of services that you can enable in your project

            gcloud services list --available

    #Using the applicable service name from the previous step, enable the service

            gcloud services enable SERVICE_NAME

    For Example:
    
            gcloud Services enable "Kubernetes Engine API"

2: Start a Kubernetes Engine cluster

    #Define the environment variable containing prefer gcp zone:

            export MY_ZONE=us-central1-a

    #Start a Kubernetes cluster managed by Kubernetes Engine. Name the cluster webfrontend and configure it to run 2 nodes

            gcloud container clusters create webfrontend --zone $MY_ZONE --num-nodes 2

        #Note: It takes several minutes to create a cluster as Kubernetes Engine provisions virtual machines for you
               The gcloud container clusters create command automatically authenticated kubectl for you


    #After the cluster is created, check your installed version of Kubernetes using the kubectl version command


3:Run and deploy a container

    #launch a single instance of the nginx container. (Nginx is a popular web server.)

            kubectl create deploy nginx --image=nginx:1.17.10

        #Note:This use of the kubectl create command caused Kubernetes to create a deployment consisting of a single pod containing the nginx container

        ##Note: If you see any deprecation warning about future version you can simply ignore it for now and can proceed further.


    #View the pod running the nginx container:

            kubectl get pods

    #Expose the nginx container to the Internet

            kubectl expose deployment nginx --port 80 --type LoadBalancer

        #Note: Kubernetes created a service and an external load balancer with a public IP address attached to it. The IP address remains the same for the life of the service. Any network traffic to that public IP address is routed to pods behind the service: in this case, the nginx pod


    #View the new service

            kubectl get services

        #Note: It may take a few seconds before the External-IP field is populated for your service. This is normal. Just re-run the kubectl get services command every few seconds until the field is populated.

    #Open a new web browser tab and paste your cluster's external IP address into the address bar. The default home page of the Nginx browser is displayed.

            curl http://External-IP

    #Scale up the number of pods running on your service


            kubectl scale deployment nginx --replicas 3


        #Note:Scaling up a deployment is useful when you want to increase available resources for an application that is becoming more popular



    #Confirm that Kubernetes has updated the number of pods:


                kubectl get pods

    #Confirm that your external IP address has not changed


                kubectl get services


    #Return to the web browser tab in which you viewed your cluster's external IP address. Refresh the page to confirm that the nginx web server is still responding.
    